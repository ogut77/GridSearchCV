{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"WFQS_bltWW_9","colab_type":"code","outputId":"8893a0f5-a65e-452f-a3e7-576c4d179c3f","colab":{"base_uri":"https://localhost:8080/","height":70},"trusted":true},"cell_type":"code","source":"dt=pd.read_csv('../input/dta3.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"G2RPlS6cDTno","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"dt=pd.get_dummies(dt)","execution_count":null,"outputs":[]},{"metadata":{"id":"vL2kPolFERq2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"dt=dt.drop(columns=['B_ELECTRONIC_AUCTION_N','PROCEDURE_RES','SECTOR_na','B_GPA_N','TYPE_OF_CONTRACT_W','CAE_TYPE_Z','AUTHORITY_COUNTRY_UK'] )","execution_count":null,"outputs":[]},{"metadata":{"id":"qBCKCDd619e0","colab_type":"code","outputId":"08abb929-7303-4a67-d20c-98bb20ab7a5f","colab":{"base_uri":"https://localhost:8080/","height":167},"trusted":true},"cell_type":"code","source":"print(dt.columns)\nlen(dt)","execution_count":null,"outputs":[]},{"metadata":{"id":"56FUVhiTaq4t","colab_type":"code","outputId":"a0653409-88cb-4435-9fd0-b4ae19c8fba8","colab":{"base_uri":"https://localhost:8080/","height":33},"trusted":true},"cell_type":"code","source":"dt = dt[pd.notnull(dt['AWARD_VALUE_EURO'])]\ndt = dt[dt['AWARD_VALUE_EURO'] != 0]\nlen(dt)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"y983RQy_2OiQ","colab_type":"code","outputId":"01c4db85-01bc-43e3-b3a0-1bfba965a96d","colab":{"base_uri":"https://localhost:8080/","height":33},"trusted":true},"cell_type":"code","source":"dt = dt[pd.notnull(dt['AWARD_EST_VALUE_EURO'])]\ndt = dt[dt['AWARD_EST_VALUE_EURO'] != 0]\nlen(dt)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"tvW0BfKb2Wc6","colab_type":"code","outputId":"627e9679-ad10-4dcc-a52e-70d6cc10666b","colab":{"base_uri":"https://localhost:8080/","height":33},"trusted":true},"cell_type":"code","source":"dt = dt[pd.notnull(dt['NUMBER_OFFERS'])]\ndt = dt[dt['NUMBER_OFFERS'] != 0]\nlen(dt)","execution_count":null,"outputs":[]},{"metadata":{"id":"URwhUOth2e0v","colab_type":"code","outputId":"64c3e1db-1627-4c27-8b52-c9784a97f36d","colab":{"base_uri":"https://localhost:8080/","height":33},"trusted":true},"cell_type":"code","source":"import numpy as np\ndt['LNRATIO']=(np.log(dt['AWARD_VALUE_EURO']/dt['AWARD_EST_VALUE_EURO']))\nlen(dt)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"lWmCx0iO3xmt","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#log of 'df_train['month'] = pd.to_datetime(df_train.Date).dt.month\ndt['LN_AWARD_VALUE_EURO'] = np.log(dt['AWARD_VALUE_EURO'])\ndt['LN_AWARD_EST_VALUE_EURO'] = np.log(dt['AWARD_EST_VALUE_EURO'])","execution_count":null,"outputs":[]},{"metadata":{"id":"mRaJ1iJ7-XcD","colab_type":"code","outputId":"50250c5d-8d7a-4cd0-fc16-5fc839c69579","colab":{"base_uri":"https://localhost:8080/","height":286},"trusted":true},"cell_type":"code","source":"dt['LNRATIO'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"id":"GtMm-QBmr4ro","colab_type":"code","outputId":"6efacb5e-196f-4bd6-a95d-30d8fa670a0e","colab":{"base_uri":"https://localhost:8080/","height":167},"trusted":true},"cell_type":"code","source":"dt['LNRATIO'].describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"PAo227hHrP6S","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"dt = dt[(dt.LNRATIO>-3) & (dt.LNRATIO<3)]\n","execution_count":null,"outputs":[]},{"metadata":{"id":"ZE4D_FXGACpc","colab_type":"code","outputId":"5d76b52d-85e1-44de-862a-d1fb4b6d782a","colab":{"base_uri":"https://localhost:8080/","height":167},"trusted":true},"cell_type":"code","source":"dt['LNRATIO'].describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"qwZeshz3KVH-","colab_type":"code","outputId":"db52181e-8ade-4455-860f-0e8594ba9197","colab":{"base_uri":"https://localhost:8080/","height":286},"trusted":true},"cell_type":"code","source":"dt['LN_AWARD_VALUE_EURO'].hist(bins=1000)","execution_count":null,"outputs":[]},{"metadata":{"id":"2R9IzhXCr2Ja","colab_type":"code","outputId":"74206540-4f4b-4d71-b716-dbd6ea826194","colab":{"base_uri":"https://localhost:8080/","height":286},"trusted":true},"cell_type":"code","source":"dt['LN_AWARD_EST_VALUE_EURO'].hist(bins=1000)","execution_count":null,"outputs":[]},{"metadata":{"id":"Nnb5AfWgcZTF","colab_type":"code","outputId":"cb0f1cbd-7d5c-44fc-ec89-933d3eeb1db4","colab":{"base_uri":"https://localhost:8080/","height":286},"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter( dt['LN_AWARD_VALUE_EURO'],dt['LN_AWARD_EST_VALUE_EURO'])","execution_count":null,"outputs":[]},{"metadata":{"id":"i-GP06HGl_lG","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train=dt[(dt.YEAR<2017)]\ntest=dt[(dt.YEAR==2017)]","execution_count":null,"outputs":[]},{"metadata":{"id":"4Bm9jfr_l_1N","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"y_train = train['LNRATIO']\nX_train = train.drop(['AWARD_VALUE_EURO', 'AWARD_EST_VALUE_EURO', 'LNRATIO', 'LN_AWARD_VALUE_EURO'], axis=1)\ny_test = test['LNRATIO']\nX_test = test.drop(['AWARD_VALUE_EURO', 'AWARD_EST_VALUE_EURO',  'LNRATIO' ,'LN_AWARD_VALUE_EURO'], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"8Rqcg7Q6clku","colab_type":"code","outputId":"326a5c66-b5bf-451c-9299-8314563e0d75","colab":{"base_uri":"https://localhost:8080/","height":150},"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"x2FKI7wmbauS","colab_type":"code","outputId":"1e960b45-7122-4d64-91e9-0eea46748677","colab":{"base_uri":"https://localhost:8080/","height":2844},"trusted":true},"cell_type":"code","source":"from sklearn import datasets, linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport statsmodels.api as sm\nmOLS = sm.OLS(y_train, X_train).fit()\nprint(mOLS.summary())\n\n\n\n# Print out the statistics\n\n# Fit and make the predictions by the model\n","execution_count":null,"outputs":[]},{"metadata":{"id":"rMTGWoqtS9YS","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import math\nfrom scipy.stats.stats import pearsonr\nfrom scipy.stats import spearmanr\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\ndef print_score(m):\n    print('Train rmse '+str(rmse(m.predict(X_train), y_train))) \n    print('Test  rmse '+str(rmse(m.predict(X_test), y_test)))\n    print('Train '+str(spearmanr(m.predict(X_train),y_train)))\n    print('Test  '+str(spearmanr(m.predict(X_test),y_test)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"id":"M-Ik3BGJXqA0","colab_type":"code","outputId":"7b360fbe-13a2-4576-eb41-beaeacf332c0","colab":{"base_uri":"https://localhost:8080/","height":84},"trusted":true},"cell_type":"code","source":"print_score(mOLS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(y_test, mOLS.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"id":"W56dz1Tfaoas","colab_type":"code","outputId":"9fbe7cec-1546-4edb-c47d-57e27edc0e3e","colab":{"base_uri":"https://localhost:8080/","height":237},"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nlg = lgb.LGBMRegressor(silent=False)\nparam_dist = {\"max_depth\": [-1,10, 50],\n              \"learning_rate\" : [0.01,0.1,0.2],\n              \"num_leaves\": [10,100,500],\n              \"n_estimators\": [200,500,1000]\n             }\ngrid_search = GridSearchCV(lg,  param_grid=param_dist, cv = 2,scoring='neg_mean_squared_error' ,verbose=5)\ngrid_search.fit(X_train,y_train)\nprint(grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"id":"a8re57kuEb31","colab_type":"code","outputId":"1df3ae65-6fed-40dc-a44c-d616cb7d7f15","colab":{"base_uri":"https://localhost:8080/","height":485},"trusted":true},"cell_type":"code","source":"import math\nfrom scipy.stats import spearmanr\nfrom sklearn.model_selection import KFold\nfrom lightgbm import LGBMRegressor\nimport gc\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\nfolds = KFold(n_splits=4, shuffle=True, random_state=42)\noof_reg_preds = np.zeros(X_train.shape[0])\nsub_reg_preds = np.zeros(X_test.shape[0])\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n    trn_x, trn_y = X_train.iloc[trn_idx], y_train.iloc[trn_idx]\n    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n    \n    reg = LGBMRegressor(**grid_search.best_params_)\n   \n    print(\"-\"* 20 + \"LightGBM Training\" + \"-\"* 20)\n    reg.fit(trn_x, trn_y, eval_set= [ (val_x, val_y)],early_stopping_rounds=100,verbose=200,eval_metric='rmse' )\n    # LightGBM\n    oof_reg_preds[val_idx] = reg.predict(val_x, num_iteration=reg.best_iteration_)\n    sub_reg_preds  += reg.predict(X_test, num_iteration=reg.best_iteration_)/ folds.n_splits\n    print('Fold %2d RMSE: %.6f' % (n_fold + 1, rmse(val_y, oof_reg_preds[val_idx])))\n    del reg, trn_x, trn_y, val_x, val_y\n    gc.collect()\n    \nprint('Full Train RMSE score %.6f' % rmse(y_train, oof_reg_preds)) \nprint('Full Test RMSE score %.6f' % rmse(y_test, sub_reg_preds))    \nprint('Train '+str(spearmanr(oof_reg_preds,y_train)))\nprint('Test  '+str(spearmanr(sub_reg_preds,y_test)))  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.scatter(y_test, sub_reg_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nmod1 = XGBRegressor()\nparam= {\"max_depth\": [10,50],\n              \"min_child_weight\" : [1,6],\n              \"n_estimators\": [200,500],\n              \"learning_rate\": [0.05, 0.2]}\nsearch1 = GridSearchCV(mod1, param,scoring='neg_mean_squared_error', cv = 2,verbose=True)\nsearch1.fit(X_train.values,y_train.values)\n\nprint(search1.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"id":"evkS1Du5QQ26","colab_type":"code","outputId":"0313e432-0ca0-44b3-a199-bffb66a167a2","colab":{"base_uri":"https://localhost:8080/","height":675},"trusted":true},"cell_type":"code","source":"xgb_params = {\n        'objective': 'reg:linear',\n        'booster': 'gbtree',\n        'learning_rate': 0.1,\n        'max_depth': 12,\n        'min_child_weight': 300,\n        'gamma' : 1.45,\n        'alpha': 0.0,\n        'lambda': 1.0,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'colsample_bylevel': 1,\n        'n_jobs': 1,\n        'random_state': 456 \n    }\nfrom sklearn.model_selection import KFold\nimport xgboost as xgb\nimport gc\nimport math\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\nfolds = KFold(n_splits=4, shuffle=True, random_state=42)\noof_reg_preds1 = np.zeros(X_train.shape[0])\nxgb_preds= np.zeros(X_test.shape[0])\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n    trn_x, trn_y = X_train.iloc[trn_idx], y_train.iloc[trn_idx]\n    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n    d_train = xgb.DMatrix(trn_x.values, trn_y.values)\n    d_valid = xgb.DMatrix(val_x.values, val_y.values)\n    d_test = xgb.DMatrix(X_test.values)\n    d_val=xgb.DMatrix(val_x.values)\n    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n    xgb.XGBRegressor(**search1.best_params_)\n    print(\"-\"* 20 + \"XGboost Training\" + \"-\"* 20)\n    xgb.train(xgb_params, d_train,100, watchlist,verbose_eval=50,early_stopping_rounds=10)\n   \n   \n    \n    \n    # Xgboost\n    oof_reg_preds1[val_idx] = xgb.predict(d_val)\n    xgb_preds += xgb.predict(d_test)/ folds.n_splits\n                        \n   \n   \n    \n    \n   \n    print('Fold %2d RMSE: %.6f' % (n_fold + 1, rmse(val_y, oof_reg_preds1[val_idx])))\n    del  trn_x, trn_y, val_x, val_y\n    gc.collect()\n    \nprint('Full RMSE score %.6f' % rmse(y_train, oof_reg_preds1)) \nprint('Full Test RMSE score %.6f' % rmse(y_test, xgb_preds))    \nprint('Train '+str(spearmanr(oof_reg_preds1,y_train)))\nprint('Test  '+str(spearmanr(xgb_preds,y_test)))  \n","execution_count":null,"outputs":[]},{"metadata":{"id":"EfD38Wibt6ed","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":8612},"outputId":"cd8a7424-cc65-49f4-addf-d938e5fc733c","trusted":false},"cell_type":"code","source":"import catboost as cb\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nparams = {'depth': [5,8,10],\n          'learning_rate' : [ 0.01,0.1,0.2],    \n         'iterations': [200,500,1000]}\ncb = cb.CatBoostRegressor()\ncb_model = GridSearchCV(cb, params, scoring='neg_mean_squared_error', cv = 2,verbose=False,n_jobs=-1)\ncb_model.fit(X_train, y_train)\nprint(cb_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cb_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"id":"Rd5K71SLn8iV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1048},"outputId":"f01b0eb9-ff7a-4e41-efc3-5fe033eccece","trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\nimport gc\nimport math\ndef rmse(x,y): return math.sqrt(((x-y)**2).mean())\nfolds = KFold(n_splits=4, shuffle=True, random_state=42)\noof_reg_preds2 = np.zeros(X_train.shape[0])\ncat_preds= np.zeros(X_test.shape[0])\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train)):\n    trn_x, trn_y = X_train.iloc[trn_idx], y_train.iloc[trn_idx]\n    val_x, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n    \n    cat = CatBoostRegressor(**cb_model.best_params_)\n   \n    print(\"-\"* 20 + \"Catboost Training\" + \"-\"* 20)\n    cat.fit(trn_x, trn_y,eval_set= [ (val_x, val_y)],early_stopping_rounds=50,use_best_model=True,verbose=100)\n    \n    \n    # catboost\n    oof_reg_preds2[val_idx] = cat.predict(val_x)\n    cat_preds +=cat.predict(X_test)/ folds.n_splits\n    \n    \n    \n   \n    print('Fold %2d RMSE: %.6f' % (n_fold + 1, rmse(val_y, oof_reg_preds2[val_idx])))\n    del  trn_x, trn_y, val_x, val_y\n    gc.collect()\n    \nprint('Full Train RMSE score %.6f' % rmse(y_train, oof_reg_preds2)) \nprint('Full Test RMSE score %.6f' % rmse(y_test, cat_preds))    \nprint('Train '+str(spearmanr(oof_reg_preds2,y_train)))\nprint('Test  '+str(spearmanr(cat_preds,y_test)))","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"EUAuction200419.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}